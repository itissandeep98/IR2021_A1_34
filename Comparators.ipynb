{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to C:\\Users\\Sajeel\n",
      "[nltk_data]     Khan\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to C:\\Users\\Sajeel\n",
      "[nltk_data]     Khan\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk.tokenize import word_tokenize\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import PorterStemmer,SnowballStemmer,WordNetLemmatizer\n",
    "import json\n",
    "import os\n",
    "from tqdm.notebook import tqdm,tnrange\n",
    "import string\n",
    "import numpy as np\n",
    "from wordcloud import WordCloud\n",
    "import matplotlib.pyplot as plt\n",
    "from collections import defaultdict\n",
    "\n",
    "nltk.download(\"punkt\")\n",
    "nltk.download(\"stopwords\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Response():\n",
    "    def __init__(self,data):\n",
    "        self.data=set(data)\n",
    "\n",
    "    def getMapping(self,file):\n",
    "        self.mapping=json.load(open(file))\n",
    "        for i in self.data:\n",
    "            print(self.mapping[i])\n",
    "    \n",
    "    def __str__(self):\n",
    "        return str(len(self.data))\n",
    "\n",
    "    def add(self,response):\n",
    "        return Response(set.union(self.data,response.data))\n",
    "        \n",
    "    def intersect(self,response):\n",
    "        return Response(set.intersection(self.data,response.data))\n",
    "\n",
    "    def diff(self,response):\n",
    "        return Response(set.difference(self.data,response.data))\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Query():\n",
    "    def __init__(self,file):\n",
    "        self.db=json.load(open(file))\n",
    "        self.db=defaultdict(lambda:[],self.db)        \n",
    "\n",
    "    def OR(self,term1,term2):\n",
    "        return term1.add(term2)\n",
    "    \n",
    "    def AND(self,term1,term2):\n",
    "        return term1.intersect(term2)\n",
    "    \n",
    "    def ANDNOT(self,term1,term2):\n",
    "        univ=Response(np.arange(468))\n",
    "        not_term2=univ.diff(term2)\n",
    "        return term1.intersect(not_term2)\n",
    "\n",
    "    def ORNOT(self,term1,term2):\n",
    "        univ=Response(np.arange(468))\n",
    "        not_term2=univ.diff(term2)\n",
    "        joint = term1.intersect(term2)\n",
    "        return not_term2.add(joint)\n",
    "\n",
    "    def no_comparisonsOR(self,term1, term2):\n",
    "        first = list(term1.data)\n",
    "        first.sort()\n",
    "        second =list(term2.data)\n",
    "        second.sort()\n",
    "        i,j,count=0,0,0\n",
    "        while(i<len(first) and j<len(second)):\n",
    "            count+=1\n",
    "            if(first[i]<second[j]):\n",
    "                i+=1          \n",
    "            elif(first[i]>second[j]):\n",
    "                j+=1\n",
    "            else:\n",
    "                i+=1\n",
    "                j+=1\n",
    "        return count    \n",
    "\n",
    "    def no_comparisonsAND(self,term1, term2):\n",
    "        first = list(term1.data)\n",
    "        first.sort()\n",
    "        second =list(term2.data)\n",
    "        second.sort()\n",
    "        i,j,count=0,0,0\n",
    "        while(i<len(first) and j<len(second)):\n",
    "            count+=1\n",
    "            if(first[i]<second[j]):\n",
    "                i+=1          \n",
    "            elif(first[i]>second[j]):\n",
    "                j+=1\n",
    "            else:\n",
    "                i+=1\n",
    "                j+=1\n",
    "        return count\n",
    "    \n",
    "    def no_comparisonsANDNOT(self,term1, term2):\n",
    "#         temp=Response(np.arange(468)) \n",
    "#         second = Response(self.db[term2]) #list of term2\n",
    "#         second=temp.diff(second) #generating Universal - (Not terms2)\n",
    "#         second=list(second.data)\n",
    "#         second.sort() #sorting, if needed\n",
    "#         first = list(set(self.db[term1])) #list of term1\n",
    "#         first.sort()\n",
    "        first = list(term1.data)\n",
    "        first.sort()\n",
    "        second =list(term2.data)\n",
    "        second.sort()\n",
    "        #initiating general AND operator\n",
    "        i,j,count=0,0,0\n",
    "        while(i<len(first) and j<len(second)):\n",
    "            count+=1\n",
    "            if(first[i]<second[j]):\n",
    "                i+=1          \n",
    "            elif(first[i]>second[j]):\n",
    "                j+=1\n",
    "            else:\n",
    "                i+=1\n",
    "                j+=1\n",
    "        return count\n",
    "    \n",
    "    def no_comparisonsORNOT(self,term1, term2):\n",
    "#         temp=Response(np.arange(468)) \n",
    "#         second = Response(self.db[term2]) #list of term2\n",
    "#         second=temp.diff(second) #generating Universal - (Not terms2)\n",
    "#         second=list(second.data)\n",
    "#         second.sort() #sorting, if needed\n",
    "#         first = self.db[term1] #list of term1\n",
    "        first = list(term1.data)\n",
    "        first.sort()\n",
    "        second =list(term2.data)\n",
    "        second.sort()\n",
    "    \n",
    "        i,j,count=0,0,0\n",
    "        while(i<len(first) and j<len(second)):\n",
    "            count+=1\n",
    "            if(first[i]<second[j]):\n",
    "                i+=1          \n",
    "            elif(first[i]>second[j]):\n",
    "                j+=1\n",
    "            else:\n",
    "                i+=1\n",
    "                j+=1\n",
    "        return count  \n",
    "\n",
    "    def stripSpecialChar(self,text):\n",
    "        return ''.join(ch for ch in text if ch.isalnum() and not ch.isdigit() and ch not in string.punctuation)\n",
    "\n",
    "    def preProcess(self,text):\n",
    "        stemmer = SnowballStemmer(\"english\")\n",
    "        stopWords = set(stopwords.words('english'))\n",
    "\n",
    "        text = text.lower()\n",
    "        text_tokens = word_tokenize(text)\n",
    "#         stemmedWords = list([stemmer.stem(word) for word in text_tokens])\n",
    "\n",
    "#         validTokens = [i for i in stemmedWords if i not in stopWords]\n",
    "        validTokens = [i for i in text_tokens if i not in stopWords]\n",
    "\n",
    "        validTokens = [self.stripSpecialChar(x) for x in validTokens]\n",
    "        validTokens = [x for x in validTokens if len(x) > 1]\n",
    "        return validTokens\n",
    "    \n",
    "    def processQuery(self,inp,ops):\n",
    "        terms=self.preProcess(inp)\n",
    "        output=Response(self.db[terms[0]])\n",
    "        comparisons=0\n",
    "        for i in tnrange(1,len(terms)):\n",
    "            curr=Response(self.db[terms[i]])\n",
    "            if(ops[i-1]=='OR'):\n",
    "                output=self.OR(output, curr)\n",
    "                comparisons+=self.no_comparisonsOR(output,curr)\n",
    "            elif(ops[i-1]=='AND'):\n",
    "                output=self.AND(output, curr)\n",
    "                comparisons+=self.no_comparisonsAND(output,curr)\n",
    "            elif(ops[i-1]=='OR NOT'):\n",
    "                output=self.ORNOT(output, curr)\n",
    "                comparisons+=self.no_comparisonsORNOT(output,curr)\n",
    "            elif(ops[i-1]=='AND NOT'):\n",
    "                output=self.ANDNOT(output, curr)\n",
    "                comparisons+=self.no_comparisonsANDNOT(output,curr)\n",
    "\n",
    "        print(\"Number of documents matched:\",output)\n",
    "        print(\"No. of comparisons required:\",comparisons)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enter the number of queries:1\n",
      "Enter the sentence:-telephone,paved, roads\n",
      "Enter the operands:-OR NOT,AND NOT\n",
      "['OR NOT', 'AND NOT']\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2d27ab47e7ce45c0a1538dc8891aaae9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=2.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Number of documents matched: 426\n",
      "No. of comparisons required: 790\n"
     ]
    }
   ],
   "source": [
    "n = int(input(\"Enter the number of queries:\"))\n",
    "for _ in range(n):\n",
    "    sentence_query = input(\"Enter the sentence:-\")\n",
    "    operands_=input(\"Enter the operands:-\").split(\",\")\n",
    "    print(operands_)\n",
    "    query=Query(\"output.json\")\n",
    "    query.processQuery(sentence_query,operands_)\n",
    "    \n",
    "    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
