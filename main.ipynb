{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3",
   "language": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "source": [
    "# Imports"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "[nltk_data] Downloading package punkt to /home/sandeep/nltk_data...\n[nltk_data]   Package punkt is already up-to-date!\n[nltk_data] Downloading package stopwords to\n[nltk_data]     /home/sandeep/nltk_data...\n[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "metadata": {},
     "execution_count": 48
    }
   ],
   "source": [
    "from nltk.tokenize import word_tokenize\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "import json\n",
    "import os\n",
    "from tqdm.notebook import tqdm,tnrange\n",
    "import string\n",
    "import numpy as np\n",
    "\n",
    "nltk.download(\"punkt\")\n",
    "nltk.download(\"stopwords\")"
   ]
  },
  {
   "source": [
    "# Inverted Index"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class InvertedIndex():\n",
    "\tdef __init__(self):\n",
    "\t\tself.db={}\n",
    "\n",
    "\tdef __str__(self):\n",
    "\t\treturn \"Keys:\"+str(len(list(self.db.keys())))\n",
    "\t\n",
    "\tdef stripSpecialChar(self,text):\n",
    "\t\treturn ''.join(ch for ch in text if ch.isalnum() and not ch.isdigit() and ch not in string.punctuation)\n",
    "\n",
    "\tdef preProcess(self,text):\n",
    "\t\ttext = text.lower()\n",
    "\t\ttext_tokens = word_tokenize(text)\n",
    "\t\tstopWords = set(stopwords.words('english'))\n",
    "\t\tvalidTokens = list(set(text_tokens) - set(stopWords))\n",
    "\t\tvalidTokens = [self.stripSpecialChar(x) for x in validTokens]\n",
    "\t\tvalidTokens = [x for x in validTokens if len(x) > 1]\n",
    "\t\treturn validTokens\n",
    "\n",
    "\tdef indexFile(self,file,fileId):\n",
    "\t\ttokens = self.preProcess(file)\n",
    "\t\tfor i in tokens:\n",
    "\t\t\tif i in self.db:\n",
    "\t\t\t\tself.db[i].append(fileId)\n",
    "\t\t\telse:\n",
    "\t\t\t\tself.db[i] = [fileId]\n",
    "\n",
    "\tdef save(self):\n",
    "\t\tjson.dump(self.db, open(\"output.json\", \"w\"))\n"
   ]
  },
  {
   "source": [
    "# Creating Index"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "  0%|          | 0/467 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "ee19d8e8e59a4fed80d818bc7c4c2b34"
      }
     },
     "metadata": {}
    }
   ],
   "source": [
    "allFiles = os.walk(\"stories\")\n",
    "filePaths = []\n",
    "for i in allFiles:\n",
    "\tfor j in i[2]:\n",
    "\t\tfilePath = i[0] + \"/\" + j\n",
    "\t\tfilePaths.append(filePath)\n",
    "\n",
    "json.dump(filePaths, open(\"mapping.json\", \"w\"))\n",
    "\n",
    "index = InvertedIndex()\n",
    "\n",
    "for i,filePath in enumerate(tqdm(filePaths)):\n",
    "    try:\n",
    "        file = open(filePath, encoding=\"utf8\")\n",
    "        read = file.read().replace('\\n', ' ')    \n",
    "    except Exception as e:\n",
    "        file = open(\"stories/tctac.txt\", encoding=\"Latin1\")\n",
    "        read = file.read().replace('\\n', ' ')\n",
    "    file.close()\n",
    "    index.indexFile(read, i)\n",
    "    index.save()\n"
   ]
  },
  {
   "source": [
    "# Query"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Query():\n",
    "    def __init__(self):\n",
    "        pass\n",
    "\n",
    "    def loadIndex(self,file):\n",
    "        self.db=json.load(open(file))\n",
    "\n",
    "    def OR(self,term1,term2):\n",
    "        return term1.add(term2)\n",
    "    \n",
    "    def AND(self,term1,term2):\n",
    "        return term1.intersect(term2)\n",
    "    \n",
    "    def ANDNOT(self,term1,term2):\n",
    "        # temp=Response(set(sum(list(self.db.copy().values()),[])))\n",
    "        temp=Response(np.arange(468))\n",
    "        temp1=temp.diff(term2)\n",
    "        return term1.intersect(temp1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Response():\n",
    "    def __init__(self,data):\n",
    "        self.data=set(data)\n",
    "\n",
    "    def getMapping(self,file):\n",
    "        self.mapping=json.load(open(file))\n",
    "        for i in self.data:\n",
    "            print(self.mapping[i])\n",
    "    \n",
    "    def __str__(self):\n",
    "        return str(len(self.data))\n",
    "\n",
    "    def add(self,response):\n",
    "        return Response(set.union(self.data,response.data))\n",
    "        \n",
    "    def intersect(self,response):\n",
    "        return Response(set.intersection(self.data,response.data))\n",
    "\n",
    "    def diff(self,response):\n",
    "        return Response(set.difference(self.data,response.data))\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "query=Query()\n",
    "query.loadIndex(\"output.json\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "  0%|          | 0/2 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "18d7f940b25341ff8a31d7703e135ee2"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "8\n"
     ]
    }
   ],
   "source": [
    "queries=[\"stink\",\"middle\",\"pronounced\"]\n",
    "output=Response(query.db[queries[0]])\n",
    "for i in tnrange(1,len(queries)):\n",
    "    curr=Response(query.db[queries[i]])\n",
    "    output=query.ANDNOT(curr,output)\n",
    "\n",
    "print(output)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "stories/grav\nstories/forgotte\nstories/wisteria.txt\nstories/ltp\nstories/abbey.txt\nstories/arcadia.sty\nstories/gulliver.txt\nstories/darkness.txt\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "{0, 35, 107, 143, 161, 194, 258, 268}"
      ]
     },
     "metadata": {},
     "execution_count": 60
    }
   ],
   "source": [
    "output.getMapping(\"mapping.json\")\n",
    "output.data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}