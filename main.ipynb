{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3",
   "language": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "source": [
    "# Imports"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "[nltk_data] Downloading package punkt to /home/sandeep/nltk_data...\n[nltk_data]   Package punkt is already up-to-date!\n[nltk_data] Downloading package stopwords to\n[nltk_data]     /home/sandeep/nltk_data...\n[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "metadata": {},
     "execution_count": 1
    }
   ],
   "source": [
    "from nltk.tokenize import word_tokenize\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "import json\n",
    "import os\n",
    "from tqdm.notebook import tqdm\n",
    "import string\n",
    "\n",
    "nltk.download(\"punkt\")\n",
    "nltk.download(\"stopwords\")"
   ]
  },
  {
   "source": [
    "# Inverted Index"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class InvertedIndex():\n",
    "\tdef __init__(self):\n",
    "\t\tself.db={}\n",
    "\n",
    "\tdef __str__(self):\n",
    "\t\treturn \"Keys:\"+str(len(list(self.db.keys())))\n",
    "\t\n",
    "\tdef stripSpecialChar(self,text):\n",
    "\t\treturn ''.join(ch for ch in text if ch.isalnum() and not ch.isdigit() and ch not in string.punctuation)\n",
    "\n",
    "\tdef preProcess(self,text):\n",
    "\t\ttext = text.lower()\n",
    "\t\ttext_tokens = word_tokenize(text)\n",
    "\t\tstopWords = set(stopwords.words('english'))\n",
    "\t\tvalidTokens = list(set(text_tokens) - set(stopWords))\n",
    "\t\tvalidTokens = [self.stripSpecialChar(x) for x in validTokens]\n",
    "\t\tvalidTokens = [x for x in validTokens if len(x) > 1]\n",
    "\t\treturn validTokens\n",
    "\n",
    "\tdef indexFile(self,file,fileId):\n",
    "\t\ttokens = self.preProcess(file)\n",
    "\t\tfor i in tokens:\n",
    "\t\t\tif i in self.db:\n",
    "\t\t\t\tself.db[i].append(fileId)\n",
    "\t\t\telse:\n",
    "\t\t\t\tself.db[i] = [fileId]\n",
    "\n",
    "\tdef save(self):\n",
    "\t\tjson.dump(self.db, open(\"output.json\", \"w\"))\n"
   ]
  },
  {
   "source": [
    "# Creating Index"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "  0%|          | 0/467 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "2d9dc9eb430b45d095187ad59ac71cd5"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "error stories/tctac.txt 'utf-8' codec can't decode byte 0xda in position 1217: invalid continuation byte\n",
      "error stories/fred.txt 'utf-8' codec can't decode byte 0xfa in position 11818: invalid start byte\n",
      "error stories/fea3 'utf-8' codec can't decode byte 0xc4 in position 1807: invalid continuation byte\n",
      "error stories/mario.txt 'utf-8' codec can't decode byte 0xc4 in position 4557: invalid continuation byte\n",
      "error stories/snow.txt 'utf-8' codec can't decode byte 0xb7 in position 6: invalid start byte\n",
      "error stories/dskool.txt 'utf-8' codec can't decode byte 0xe9 in position 32406: invalid continuation byte\n",
      "error stories/bureau.txt 'utf-8' codec can't decode byte 0xa0 in position 152695: invalid start byte\n",
      "error stories/prince.art 'utf-8' codec can't decode byte 0xdc in position 1: invalid continuation byte\n",
      "error stories/quot 'utf-8' codec can't decode byte 0xc9 in position 0: invalid continuation byte\n",
      "error stories/girlclub.txt 'utf-8' codec can't decode byte 0xd4 in position 3952: invalid continuation byte\n",
      "error stories/breaks2.asc 'utf-8' codec can't decode byte 0xc4 in position 2549: invalid continuation byte\n",
      "error stories/s&m_plot 'utf-8' codec can't decode byte 0xdc in position 1: invalid continuation byte\n",
      "error stories/friend.s 'utf-8' codec can't decode byte 0xdc in position 1: invalid continuation byte\n",
      "error stories/bishop00.txt 'utf-8' codec can't decode byte 0xa9 in position 10781: invalid start byte\n",
      "error stories/deathmrs.d 'utf-8' codec can't decode byte 0x82 in position 4023: invalid start byte\n",
      "error stories/write 'utf-8' codec can't decode byte 0xc9 in position 0: invalid continuation byte\n",
      "error stories/korea.s 'utf-8' codec can't decode byte 0xdc in position 1: invalid continuation byte\n",
      "error stories/myeyes 'utf-8' codec can't decode byte 0xc9 in position 0: invalid continuation byte\n",
      "error stories/breaks1.asc 'utf-8' codec can't decode byte 0xc4 in position 15426: invalid continuation byte\n",
      "error stories/toilet.s 'utf-8' codec can't decode byte 0xdc in position 1: invalid continuation byte\n",
      "error stories/panama.txt 'utf-8' codec can't decode byte 0xa0 in position 5390: invalid start byte\n",
      "error stories/imonly17.txt 'utf-8' codec can't decode byte 0xc9 in position 0: invalid continuation byte\n",
      "error stories/ab40thv.txt 'utf-8' codec can't decode byte 0xa5 in position 9285: invalid start byte\n",
      "error stories/history5.txt 'utf-8' codec can't decode byte 0xdb in position 35767: invalid continuation byte\n",
      "error stories/sight.txt 'utf-8' codec can't decode byte 0xbd in position 8: invalid start byte\n",
      "error stories/s&m_that 'utf-8' codec can't decode byte 0xdc in position 1: invalid continuation byte\n",
      "error stories/breaks3.asc 'utf-8' codec can't decode byte 0xc4 in position 4751: invalid continuation byte\n",
      "error stories/archive 'utf-8' codec can't decode byte 0x92 in position 92402: invalid start byte\n",
      "error stories/wrt 'utf-8' codec can't decode byte 0xda in position 24: invalid continuation byte\n",
      "error stories/SRE/sre05.txt 'utf-8' codec can't decode byte 0xc4 in position 849: invalid continuation byte\n"
     ]
    }
   ],
   "source": [
    "allFiles = os.walk(\"stories\")\n",
    "filePaths = []\n",
    "for i in allFiles:\n",
    "\tfor j in i[2]:\n",
    "\t\tfilePath = i[0] + \"/\" + j\n",
    "\t\tfilePaths.append(filePath)\n",
    "\n",
    "json.dump(filePaths, open(\"mapping.json\", \"w\"))\n",
    "\n",
    "index = InvertedIndex()\n",
    "\n",
    "for i,filePath in enumerate(tqdm(filePaths)):\n",
    "    try:\n",
    "        file = open(filePath, encoding=\"utf8\")\n",
    "        read = file.read().replace('\\n', ' ')\n",
    "        file.close()\n",
    "        index.indexFile(read, i)\n",
    "        index.save()\n",
    "    \n",
    "    except Exception as e:\n",
    "        print(\"error\", filePath,e)\n"
   ]
  },
  {
   "source": [
    "# Query"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Query():\n",
    "    def __init__(self):\n",
    "        pass\n",
    "\n",
    "    def loadIndex(self,file):\n",
    "        self.db=json.load(open(file))\n",
    "\n",
    "    def OR(self,term1,term2):\n",
    "        return term1.add(term2)\n",
    "    \n",
    "    def AND(self,term1,term2):\n",
    "        return term1.intersect(term2)\n",
    "    \n",
    "    def ANDNOT(self,term1,term2):\n",
    "        temp=Response(sum(list(self.db.copy().values()),[]))\n",
    "        temp1=temp.diff(term2)\n",
    "        return term1.intersect(temp1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Response():\n",
    "    def __init__(self,data):\n",
    "        print(data)\n",
    "        self.data=set(data)\n",
    "    \n",
    "    def __str__(self):\n",
    "        return str(len(self.data))\n",
    "\n",
    "    def add(self,response):\n",
    "        return Response(set.union(self.data,response.data))\n",
    "        \n",
    "    def intersect(self,response):\n",
    "        return Response(set.intersection(self.data,response.data))\n",
    "\n",
    "    def diff(self,response):\n",
    "        return Response(set.difference(self.data,response.data))\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query=Query()\n",
    "query.loadIndex(\"output.json\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a=Response(query.db[\"stink\"])\n",
    "b=Response(query.db[\"pronounced\"])\n",
    "print(query.OR(a,b).data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "queries=[\"stink\",\"middle\",\"pronounced\"]\n",
    "output=Response(query.db[queries[0]])\n",
    "for i in range(1,len(queries)):\n",
    "    curr=Response(query.db[queries[i]])\n",
    "    output=query.ANDNOT(curr,output)\n",
    "\n",
    "print(output)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}